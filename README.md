# Research on Neural Networks with Nonlinear Synapses

##  Part 1:

Benchmark on two linear algebra libraries setup: Numpy with Python, and Breeze with Scala. 

The operations that we used the most in a neural networks are matrix multiplication, matrix apply (apply operation elementwise), and matrix dot multiplication (elementwise multiplication). 



##  Part 2: 

A Python/Numpy implementation of ordinary linear neural networks, and a corresponding sequential implementation in Scala/Breeze; both trained on MNIST handwritten digit database. 


##	Part 3:

A Scala/Breeze implementation of neural networks with nonlinear synapses, trained on MNIST handwritten digit database. 


##	Part 4:

Using gradient checking to check the correctness of the neural networks with nonlinear sysnapses. 


##	Part 5:

A Scala/Breeze implementation of a variation of neural networks with nonliear sysapses - each transformation function (synapse) now only keep one exponent term. We call this as neural networks with single term nonlinear synapse. 


## Part 6:

Test the two kinds of nonlinear networks on XOR classification - a classical problem, that for ordinary neural networks with sigmoid activation function, they need minimum 5 noods in 3 layers, including the input layer. 


## Part 7: 

Test 
